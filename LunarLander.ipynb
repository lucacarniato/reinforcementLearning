{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREDIT: https://pythonprogramming.net/introduction-reinforcement-learning-stable-baselines-3-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\apps\\python_3_8_6\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import os\n",
    "from stable_baselines3 import A2C, PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The lunar lander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2') \n",
    "env.reset()\n",
    "\n",
    "for step in range(200):\n",
    "    env.render()\n",
    "    # take random action\n",
    "    env.step(env.action_space.sample())\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a stable baselines 3 algorithm to compute the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models at different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"PPO\"\n",
    "models_dir = \"models/\" + model_name\n",
    "logdir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "if model_name ==\"PPO\":\n",
    "    model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=logdir)\n",
    "elif model_name ==\"A2C\":\n",
    "    model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 94.1     |\n",
      "|    ep_rew_mean     | -183     |\n",
      "| time/              |          |\n",
      "|    fps             | 780      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 91.7         |\n",
      "|    ep_rew_mean          | -169         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 867          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050810706 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.00583      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 901          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00897     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.7         |\n",
      "|    ep_rew_mean          | -166         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 825          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049546617 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -0.000607    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 476          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 948          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 106        |\n",
      "|    ep_rew_mean          | -155       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 838        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00877473 |\n",
      "|    clip_fraction        | 0.0623     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | -0.019     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 260        |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.00956   |\n",
      "|    value_loss           | 689        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -158        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 867         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011486158 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.059       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 305         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -161     |\n",
      "| time/              |          |\n",
      "|    fps             | 1640     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | -150        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1215        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005633264 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.11       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 715         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 116         |\n",
      "|    ep_rew_mean          | -144        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1127        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009721042 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 6.6e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.2        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -142        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1070        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466988 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.309      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 403         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 126         |\n",
      "|    ep_rew_mean          | -145        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1032        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009780761 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.000986   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 131      |\n",
      "|    ep_rew_mean     | -140     |\n",
      "| time/              |          |\n",
      "|    fps             | 1550     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -128        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1191        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014178602 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.000187   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | -118        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1071        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009380927 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.0487      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 161         |\n",
      "|    ep_rew_mean          | -103        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 898         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009056841 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.0599      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | -92.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 886         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007952155 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | -85.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 1242     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 197         |\n",
      "|    ep_rew_mean          | -81.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 831         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007773244 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 209         |\n",
      "|    ep_rew_mean          | -79.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 812         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012090715 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.9        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 225         |\n",
      "|    ep_rew_mean          | -78.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 740         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010050362 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.0258     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 239         |\n",
      "|    ep_rew_mean          | -75.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 706         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005347975 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 260      |\n",
      "|    ep_rew_mean     | -71.5    |\n",
      "| time/              |          |\n",
      "|    fps             | 693      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 274         |\n",
      "|    ep_rew_mean          | -70.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008478386 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 75.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 288          |\n",
      "|    ep_rew_mean          | -64.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071379775 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | -0.0382      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 87.3         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | -59.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010136433 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.5        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | -50.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007299626 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42          |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 328      |\n",
      "|    ep_rew_mean     | -47.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | -48.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062601916 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.821       |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.2         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 35.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | -50.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007233047 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | -45         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005486654 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 385          |\n",
      "|    ep_rew_mean          | -39.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076138284 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.959       |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 76.6         |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 396      |\n",
      "|    ep_rew_mean     | -34.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 887      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 402         |\n",
      "|    ep_rew_mean          | -36.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857579 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.895      |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | -30.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008245307 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 435         |\n",
      "|    ep_rew_mean          | -27.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006735217 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 439          |\n",
      "|    ep_rew_mean          | -27.6        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098894145 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.836       |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 61.1         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0099      |\n",
      "|    value_loss           | 139          |\n",
      "------------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 453      |\n",
      "|    ep_rew_mean     | -26.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 1034     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 73728    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 469         |\n",
      "|    ep_rew_mean          | -20.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 827         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010046227 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 483         |\n",
      "|    ep_rew_mean          | -13.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027990744 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 497         |\n",
      "|    ep_rew_mean          | -4.34       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015817184 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 506         |\n",
      "|    ep_rew_mean          | 2.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010040533 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 513      |\n",
      "|    ep_rew_mean     | 13.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 1073     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 83968    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 515          |\n",
      "|    ep_rew_mean          | 17.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 860          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042549116 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 158          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 173          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 522         |\n",
      "|    ep_rew_mean          | 25.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 795         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005715538 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 263         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 527          |\n",
      "|    ep_rew_mean          | 39.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 754          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050176177 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.815       |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.5         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 525          |\n",
      "|    ep_rew_mean          | 44.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047278604 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.748       |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55           |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 524      |\n",
      "|    ep_rew_mean     | 54.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 1080     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 94208    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 525         |\n",
      "|    ep_rew_mean          | 62.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 747         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004958462 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 528         |\n",
      "|    ep_rew_mean          | 70.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005943885 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 520         |\n",
      "|    ep_rew_mean          | 74.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 670         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005201189 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 523          |\n",
      "|    ep_rew_mean          | 85.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051635704 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.755       |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 94.2         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "for i in range(10):\n",
    "    iters += 1\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=model_name)\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1cccc8598489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# pass observation to model to get predicted action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# pass action to env and get info back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mused\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \"\"\"\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m         \u001b[1;31m# Convert to numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTaken\u001b[0m \u001b[0maction\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mget_distribution\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0mlatent_pi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_actor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategoricalDistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;31m# Here mean_actions are the logits before the softmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiCategoricalDistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m             \u001b[1;31m# Here mean_actions are the flattened logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\stable_baselines3\\common\\distributions.py\u001b[0m in \u001b[0;36mproba_distribution\u001b[1;34m(self, action_logits)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mproba_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_logits\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"CategoricalDistribution\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_logits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\apps\\python_3_8_6\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`logits` parameter must be at least one-dimensional.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# Normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "model_path = f\"{models_dir}/100000.zip\"\n",
    "\n",
    "if model_name ==\"PPO\":\n",
    "    model = PPO.load(model_path, env=env)\n",
    "elif model_name ==\"A2C\":\n",
    "    model = A2C.load(model_path, env=env)\n",
    "    \n",
    "\n",
    "\n",
    "episodes = 10\n",
    "for ep in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # pass observation to model to get predicted action\n",
    "        action, _states = model.predict(obs)\n",
    "        # pass action to env and get info back\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        \n",
    "        # show the environment on the screen\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
