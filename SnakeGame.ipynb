{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREDIT: https://pythonprogramming.net/custom-environment-reinforcement-learning-stable-baselines-3-tutorial/?completed=/saving-and-loading-reinforcement-learning-stable-baselines-3-tutorial/"
   ]
  },
  {
   "attachments": {
    "SnakeGame.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SnakeGame.jpg](attachment:SnakeGame.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The snake game costumized enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-24-73e032a13e9d>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-73e032a13e9d>\"\u001b[1;36m, line \u001b[1;32m65\u001b[0m\n\u001b[1;33m    self.total_reward = (self.initial_distance - euclidean_dist_to_apple)/self.initial_distance + \\\u001b[0m\n\u001b[1;37m                                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "def collision_with_apple(apple_position):\n",
    "    apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "    return apple_position\n",
    "\n",
    "def collision_with_boundaries(snake_head):\n",
    "    if snake_head[0]>=500 or snake_head[0]<0 or snake_head[1]>=500 or snake_head[1]<0 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def collision_with_self(snake_position):\n",
    "    snake_head = snake_position[0]\n",
    "    if snake_head in snake_position[1:]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "class SnakeEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(SnakeEnv, self).__init__()\n",
    "        \n",
    "        self.max_snake_length = 10\n",
    "        self.snake_obs = self.max_snake_length * 2\n",
    "        self.snake_initial_length = 3\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # Example for using image as input (channel-first; channel-last also works):\n",
    "        self.observation_space = spaces.Box(low=-500, high=500, shape=(5+self.snake_obs,), dtype=np.float32)\n",
    "        # however long we aspire the snake to be\n",
    "        self.snake_body = deque(maxlen = self.snake_obs) \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # Change the head position based on the button direction\n",
    "        if action == 1:\n",
    "            self.snake_head[0] += 10\n",
    "        elif action == 0:\n",
    "            self.snake_head[0] -= 10\n",
    "        elif action == 2:\n",
    "            self.snake_head[1] += 10\n",
    "        elif action == 3:\n",
    "            self.snake_head[1] -= 10\n",
    "\n",
    "        # Increase Snake length on eating apple\n",
    "        apple_reward = 0.0\n",
    "        if self.snake_head == self.apple_position:\n",
    "            self.apple_position = collision_with_apple(self.apple_position)\n",
    "            self.snake_position.insert(0,list(self.snake_head))\n",
    "            apple_reward = 2.0 *(len(self.snake_position)-self.snake_initial_length)\n",
    "        else:\n",
    "            self.snake_position.insert(0,list(self.snake_head))\n",
    "            self.snake_position.pop()\n",
    "        \n",
    "        # On collision kill the snake\n",
    "        if collision_with_boundaries(self.snake_head) == 1 or collision_with_self(self.snake_position) == 1:\n",
    "            self.done = True\n",
    "            self.reward = -2.0\n",
    "        else:\n",
    "            euclidean_dist_to_apple = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position))\n",
    "            self.total_reward = (self.initial_distance - euclidean_dist_to_apple)/self.initial_distance + \\ \n",
    "                                apple_reward + \n",
    "                                (len(self.snake_position)-self.snake_initial_length)/self.max_snake_length \n",
    "            self.reward = self.total_reward - self.prev_total_reward\n",
    "            self.prev_total_reward = self.total_reward\n",
    "        \n",
    "        observation = self._compute_observation()\n",
    "        \n",
    "        return observation, self.reward, self.done, {}\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        # Initial Snake and Apple position\n",
    "        self.snake_position = [[250,250],[240,250],[230,250]]\n",
    "        self.apple_position = [random.randrange(1,50)*10,random.randrange(1,50)*10]\n",
    "        self.snake_head = [250,250]\n",
    "        self.initial_distance = np.linalg.norm(np.array(self.snake_head) - np.array(self.apple_position)) + 1.0e-6\n",
    "        \n",
    "        self.prev_total_reward = 0.0\n",
    "        \n",
    "        # empty actions\n",
    "        for i in range(self.snake_obs):\n",
    "            self.snake_body.append(-1) \n",
    "            \n",
    "        self.done = False\n",
    "        observation = self._compute_observation()\n",
    "        \n",
    "        return observation\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        \n",
    "        # Create image\n",
    "        self.img = np.zeros((500,500,3),dtype='uint8')        \n",
    "        # Display Apple\n",
    "        cv2.rectangle(self.img,(self.apple_position[0],self.apple_position[1]),(self.apple_position[0]+10,self.apple_position[1]+10),(0,0,255),3)\n",
    "        \n",
    "        # Display Snake\n",
    "        for position in self.snake_position:\n",
    "            cv2.rectangle(self.img,(position[0],position[1]),(position[0]+10,position[1]+10),(0,255,0),3)\n",
    "            \n",
    "        # Display collision text\n",
    "        if collision_with_boundaries(self.snake_head) == 1 or collision_with_self(self.snake_position) == 1:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            self.img = np.zeros((500,500,3),dtype='uint8')\n",
    "            cv2.putText(self.img,'Snake length {}'.format(len(self.snake_position)),(140,250), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('a',self.img)\n",
    "        cv2.waitKey(10)\n",
    "    \n",
    "    def _compute_observation(self):\n",
    "        head_x = self.snake_head[0]\n",
    "        head_y = self.snake_head[1]\n",
    "        \n",
    "        snake_length = len(self.snake_position)\n",
    "        apple_delta_x = self.apple_position[0] - head_x\n",
    "        apple_delta_y = self.apple_position[1] - head_y\n",
    "\n",
    "        for i in range(1,len(self.snake_position)):\n",
    "            self.snake_body.append(self.snake_position[i-1][0] -self.snake_position[i][0]) \n",
    "            self.snake_body.append(self.snake_position[i-1][1] -self.snake_position[i][1]) \n",
    "            \n",
    "\n",
    "        observation = [head_x, head_y, apple_delta_x, apple_delta_y, snake_length] + list(self.snake_body) \n",
    "        observation = np.array(observation)\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward -0.065537969306497\n",
      "reward -2.0\n",
      "reward -0.03158096241867012\n",
      "reward -2.0\n",
      "reward 0.05485838465229894\n",
      "reward -0.008030234495099056\n",
      "reward -2.0\n",
      "reward 0.020573634623832354\n",
      "reward 0.0644924545737275\n",
      "reward -0.02199086872301456\n",
      "reward 0.06245015321260135\n",
      "reward -0.028010624010654142\n",
      "reward -2.0\n",
      "reward -0.057016524497541035\n",
      "reward -0.059636313520415596\n",
      "reward 0.0480203985432958\n",
      "reward -0.06448299908780675\n",
      "reward -0.04539585415585243\n",
      "reward -2.0\n"
     ]
    }
   ],
   "source": [
    "env = SnakeEnv()\n",
    "episodes = 5\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    while not done:\n",
    "        random_action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(random_action)\n",
    "        #env.render()\n",
    "        print('reward',reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a stable baselines 3 algorithm to compute the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SnakeEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"PPO\"\n",
    "models_dir = \"models/\" + model_name\n",
    "logdir = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save models at different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "if model_name ==\"PPO\":\n",
    "    model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=logdir)\n",
    "elif model_name ==\"A2C\":\n",
    "    model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\PPO_0\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 4.44      |\n",
      "|    ep_rew_mean     | -1.41e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 2164      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 0         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | -2.12       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1515        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409589 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 1.03e+11    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.21        |\n",
      "|    ep_rew_mean          | -1.98       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1335        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020535849 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0082     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.8         |\n",
      "|    ep_rew_mean          | -1.89       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024283245 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.295      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.052      |\n",
      "|    value_loss           | 0.0262      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.8        |\n",
      "|    ep_rew_mean          | -1.86      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1234       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02322923 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | -0.129     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0493    |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0494    |\n",
      "|    value_loss           | 0.0309     |\n",
      "----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.95     |\n",
      "|    ep_rew_mean     | -1.73    |\n",
      "| time/              |          |\n",
      "|    fps             | 2235     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 12288    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | -1.69       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1453        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019876562 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.941      |\n",
      "|    explained_variance   | 0.0553      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0298     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.3        |\n",
      "|    ep_rew_mean          | -1.59       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1309        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013727214 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0347      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.0921      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.9        |\n",
      "|    ep_rew_mean          | -1.55       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1255        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012778973 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.0408      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.6        |\n",
      "|    ep_rew_mean          | -1.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1222        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014986711 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.045       |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.6     |\n",
      "|    ep_rew_mean     | -1.61    |\n",
      "| time/              |          |\n",
      "|    fps             | 2212     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 22528    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.8        |\n",
      "|    ep_rew_mean          | -1.37       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1480        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012104364 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.835       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 21.5         |\n",
      "|    ep_rew_mean          | -1.33        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1344         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0112962965 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.699       |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0395       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0208      |\n",
      "|    value_loss           | 0.0825       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.8        |\n",
      "|    ep_rew_mean          | -1.32       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1279        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595283 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.078       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 22.3       |\n",
      "|    ep_rew_mean          | -1.36      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1238       |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01329709 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.664     |\n",
      "|    explained_variance   | 0.588      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00914   |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    value_loss           | 0.0492     |\n",
      "----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | -1.31    |\n",
      "| time/              |          |\n",
      "|    fps             | 2232     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 32768    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.1        |\n",
      "|    ep_rew_mean          | -1.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1483        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014172388 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.0529      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.1        |\n",
      "|    ep_rew_mean          | -1.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1332        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426274 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0401      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.5       |\n",
      "|    ep_rew_mean          | -1.45      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1262       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01197556 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.609     |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0169     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 0.0783     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | -1.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1227        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011173429 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.614      |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.9     |\n",
      "|    ep_rew_mean     | -1.25    |\n",
      "| time/              |          |\n",
      "|    fps             | 2169     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 43008    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.3        |\n",
      "|    ep_rew_mean          | -1.26       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1400        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017693996 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.609       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.0889      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.1        |\n",
      "|    ep_rew_mean          | -2.24e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1290        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017327778 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.0886      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.9        |\n",
      "|    ep_rew_mean          | -1.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1251        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015565265 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0052      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 3.01e+11    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.2        |\n",
      "|    ep_rew_mean          | -1.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1220        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932822 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0752      |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | -1.19    |\n",
      "| time/              |          |\n",
      "|    fps             | 2196     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 53248    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32          |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1450        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014881536 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00992     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.4        |\n",
      "|    ep_rew_mean          | -1.29       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1324        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012832901 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1241        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875729 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.951       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | -1.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1183        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018673263 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.175       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "Logging to logs\\PPO_0\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | -1.12    |\n",
      "| time/              |          |\n",
      "|    fps             | 2248     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 63488    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | -1.21       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1527        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022573672 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0882      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.6        |\n",
      "|    ep_rew_mean          | -1.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1373        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017766142 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0505      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.0965      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 10000\n",
    "iters = 0\n",
    "for i in range(20):\n",
    "    iters += 1\n",
    "    model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=model_name)\n",
    "    model.save(f\"{models_dir}/{TIMESTEPS*iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "model_path = f\"{models_dir}/160000.zip\"\n",
    "\n",
    "if model_name ==\"PPO\":\n",
    "    model = PPO.load(model_path, env=env)\n",
    "elif model_name ==\"A2C\":\n",
    "    model = A2C.load(model_path, env=env)\n",
    "\n",
    "episodes = 50\n",
    "for ep in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        # pass observation to model to get predicted action\n",
    "        action, _states = model.predict(obs)\n",
    "        # pass action to env and get info back\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        \n",
    "        # show the environment on the screen\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
